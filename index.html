<!doctype html>
<meta charset=utf-8>
<head>
<title>Audio latency tool</title>
</head>
<body>
    <p id="instructions"></p>
    <div id="test"></div>
    <div id="log"></div>
</body>
<input type="button" value="Start" id="start" />
<input type="button" value="Stop" id="stop" />
<input type="button" value="pause" id="pause" />
<input type="button" value="play" id="play"/>
<br><br>
<input type="button" value="Show Audio Devices" id="showDevices" />

<script>

var pc1,pc2,ctx, micCaptureStream, audio,oscillator,pannode,dst,gainnode;
ctx = new AudioContext();

// Monitor AudioContext for system audio information
console.log('AudioContext Info:', {
    sampleRate: ctx.sampleRate,
    state: ctx.state,
    baseLatency: ctx.baseLatency || 'Unknown',
    outputLatency: ctx.outputLatency || 'Unknown'
});

// Listen for AudioContext state changes (can indicate system audio changes)
ctx.addEventListener('sinkchange', () => {
    console.log('AudioContext state changed to:', ctx.state);
});

//ctx.suspend();

oscillator = ctx.createOscillator();
gainnode = ctx.createGain();
oscillator.connect(gainnode);
dst = ctx.createMediaStreamDestination();

// Stereo
var channels = 2;

function instructions(text) {
    if(!text) {
        document.getElementById('instructions').innerText = '';
        return;
    }
    document.getElementById('instructions').innerText += text + '\n';
}

document.getElementById("start").onclick = async() =>
{
    instructions(); // clear instructions.
 
    audio = document.createElement('audio');
    
    // Try to detect available audio devices
    try {
        const devices = await navigator.mediaDevices.enumerateDevices();
        const audioOutputs = devices.filter(device => device.kind === 'audiooutput');
        instructions(`Found ${audioOutputs.length} audio output devices`);
        
        // Log device info
        audioOutputs.forEach((device, index) => {
            console.log(`Audio Device ${index + 1}:`, device.label || 'Unknown Device', device.deviceId);
        });
        
        // Try to detect default device
        const defaultDevice = audioOutputs.find(device => 
            device.deviceId === 'default' || device.label.toLowerCase().includes('default')
        );
        if (defaultDevice) {
            instructions(`Default device: ${defaultDevice.label || 'Unknown Device'}`);
        }
    } catch (error) {
        instructions(`Device enumeration failed: ${error.message}`);
    }
    
    // Monitor device changes
    navigator.mediaDevices.addEventListener('devicechange', () => {
        instructions('Audio device configuration changed!');
        console.log('Audio devices changed');
    });

    // Add event listeners for audio state changes
    audio.addEventListener('ended', () => {
        instructions('Audio playback ended');
        console.log('Audio ended');
    });
    
    audio.addEventListener('pause', () => {
        instructions('Audio playback paused');
        console.log('Audio paused');
    });
    
    audio.addEventListener('volumechange', (e) => {
        if (audio.muted) {
            instructions('Audio muted');
            console.log('Audio muted');
        } else if (audio.volume === 0) {
            instructions('Audio volume set to 0');
            console.log('Audio volume is 0');
        } else {
            instructions(`Audio volume changed to: ${(e.target.value * 100).toFixed(0)}%`);
            console.log('Audio volume changed to:', audio.volume);
        }
    });
    
    audio.addEventListener('play', () => {
        instructions('Audio started playing');
        console.log('Audio started playing');
    });
    
    audio.addEventListener('loadstart', () => {
        instructions('Audio loading started');
        console.log('Audio loading started');
    });
    
    audio.addEventListener('canplay', () => {
        instructions('Audio can start playing');
        console.log('Audio can start playing');
    });
    
    audio.addEventListener('error', (e) => {
        instructions(`Audio error occurred: ${e.message || 'Unknown error'}`);
        console.log('Audio error:', e);
    });

    audio.addEventListener("suspend", (event) => {
        console.log("Data loading has been suspended.");
    });

    audio.addEventListener("ended", (event) => {
  console.log(
    "Video stopped either because it has finished playing or no further data is available.",
  );
});

audio.addEventListener("stalled", (event) => {
  console.log("Failed to fetch data, but trying.");
});
    
    // The actual test.

    instructions('This is a manual test that verifies stereo audio');
    instructions('Click the button to start the test.');

	//ctx.resume();
    //audio.play()

    pc1 = new RTCPeerConnection();
    pc2 = new RTCPeerConnection();
    
    pc1.onicecandidate = e => e.candidate && pc2.addIceCandidate(e.candidate);
    pc2.onicecandidate = e => e.candidate && pc1.addIceCandidate(e.candidate);
    dst.stream.getTracks().forEach(t => pc1.addTrack(t, dst.stream));
    pc2.ontrack = e => audio.srcObject = e.streams[0];

    instructions('Attempting to establish WebRTC connection...');
    const offer = await pc1.createOffer();
    await pc1.setLocalDescription(offer)
    await pc2.setRemoteDescription(offer);
    const answer = await pc2.createAnswer();
    // Here is the trick for stereo: SDP munging!
    await pc2.setLocalDescription({type: 'answer', sdp: answer.sdp.replace('useinbandfec=1', 'useinbandfec=1;stereo=1')});
    await pc1.setRemoteDescription({type: 'answer', sdp: answer.sdp.replace('useinbandfec=1', 'useinbandfec=1;stereo=1')});
    await (new Promise((resolve, reject) => {
        if (pc2.connectionState === 'connected') return resolve();
        pc2.onconnectionstatechange = e => {
            if (pc2.connectionState === 'connected') {
                resolve();
				instructions('WebRTC connection established');
				gainnode.connect(dst);
				oscillator.start();
            }
        };       
    }))
}

document.getElementById("stop").onclick = () => {
            pc1.close();
			pc2.close();
			ctx.close();
}

document.getElementById("pause").onclick = () => {
		audio.pause();
}

document.getElementById("play").onmousedown = () => {
		audio.play();
}

document.getElementById("showDevices").onclick = async () => {
    try {
        
        instructions(`AudioContext: ${ctx.sampleRate}Hz, State: ${ctx.state}`);
        
    } catch (error) {
        instructions(`Device enumeration error: ${error.message}`);
    }
}
</script>   
</html>